#! /usr/bin/env python3
"""
# NAME
run - Quickly queue and run jobs from the command line.

# VERSION: 0.4.0

Note: Before version 0.4.0, `run` was a Perl script. For version 0.4.0, `run` was completely rewritten in Python.

# DESCRIPTION

  `run` is a perl script that will run a set of commands.
  It is primarily useful for running commands that are expected to run for a long
  time, such as physics simulations.  `run` uses "handlers" to actually run the
  commands, and tries to automatically select the best handler to use to complete
  the runs as quickly as possible. For example, if you are working on a cluster
  and the `qsub` command exists, `run` will create submission scripts and submit
  them to the scheduler.  If the `qsub` command does not exist, then other handlers
  are checked. For example, if the `parallel` (gnu parallel) or `xjobs` commands
  are found, they can be used to run all commands in parallel.

  If all other handlers fail, `run` will fall back to just running each command
  in serial, one after the other.  This turns out to still be useful, because if
  you have a set of simulations that you need to perform, you can use `run` to
  automatically run each simulation after one has completed.

  All handlers will first create a script wrapper for each command to run and
  then run this script.  This is done so that extra information can be embedded
  in the command output, such as a time stamp for timing data.


  Current Handlers

  `slurm`

  This handler uses the `sbatch` command. `sbatch` is used to submit jobs to
  an HPC cluster using the Slurm workload manager, which is become popular
  in recent years. The `sbatch` handler will automatically
  create a submission script for each job and subit the scripts to the scheduler.
  This is handy if you want to just quickly submit a basic job that does not
  require a complex submission script.


  `gnuparallel`

  This handler uses the `parallel` command, from the gnuparallel project. `parallel` is a
  perl script that runs multiple jobs in parallel and even supports running jobs on remote computers
  (not supported by run). It attempts to work as a parallel version of `xargs`.

  `xjobs`

  This handler uses the `xjobs` command. `xjobs` is a small C program written by Thomas Maier-Komer that
  that a command multiple times with different arguments in parallel.
  It strives to be a parallel version of `xargs`.

  `serial`

  This handler just runs each job directly, one after the other.


  Possible Future Handlers

  - `pexec` another tool for running jobs in parallel on a workstation.
  - `pbs` a common (maybe the most common) scheduler interface used on clusters.


  Note that `run` does not do load balancing. Each handler is given the list of commands to run, and they are responsible
  for managing the system workload.

# EXAMPLES

  run 3 scripts

      > run script1.sh : script2.sh : script3.sh

  run 3 BTEC runs

      > run -C BTECthermal config1.btec : BTECthermal config2.btec : BTECthermal config3.btec

  run BTEC for all config files in the current directory

      > run -C BTECthermal -d' ' config*.btec

  run 3 scripts using the gnuparallel handler

      > run -H gnuparallel script1.sh : script2.sh : script3.sh

  get a list of all handlers

      > run -l

# INSTALLATION

  `run` is a single python script that uses only standard library modules.
  To install it, just place it somewhere in your PATH.


# LICENSE

  The MIT License (MIT)

  Copyright (c) 2015-present CD Clark III

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to deal
  in the Software without restriction, including without limitation the rights
  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
  copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
  THE SOFTWARE.
"""

from __future__ import print_function
from __future__ import unicode_literals
import subprocess
import os, sys, inspect, logging, shutil, re, json, hashlib, tempfile, stat, io
from argparse import ArgumentParser

handler_priority = [
    'slurm',
    'xjobs',
    'gnuparallel',
  ]



class workdir(object):
  '''
  A context class to temporarily change working directory.
  '''
  def __init__(self, path):
    self.old_dir = os.getcwd()
    self.new_dir = path

  def __enter__(self):
    if self.new_dir is not None:
      os.chdir(self.new_dir)

  def __exit__(self, *args):
    if self.new_dir is not None:
      os.chdir(self.old_dir)

def run(cmd,wd=None,capture_output=False,input=None):
  '''Run a command and return its exit status, standard output, and standard error.'''
  try: input = input.encode('utf-8')
  except: pass 

  stdout = None
  if capture_output:
    stdout = subprocess.PIPE

  with workdir(wd):
    c = subprocess.run( cmd, shell=True, executable="/bin/bash", input=input, stdout=stdout,stderr=subprocess.STDOUT)

  r = c.returncode
  o = c.stdout

  try:
    o = o.decode('utf-8')
  except: pass

  return r,o

def qx(cmd,wd=None):
  '''Run a command and returns its output.'''
  r,o = run(cmd,wd)
  return o

def render(text,context,opts=dict()):
  for k in context:
    text = text.replace("<%"+k+"%>",context[k])
  # remove any left over keys
  if 'remove_missing_keys' not in opts or opts['remove_missing_keys']:
    text = re.sub("<%.*%>","",text)

  return text

def generate_name(cmd_str):
  if len(cmd_str) > 20:
    return "_"+hashlib.sha1(cmd_str.encode("utf-8")).hexdigest()

  return cmd_str.replace(" ","_")

#  _   _                 _ _               
# | | | | __ _ _ __   __| | | ___ _ __ ___ 
# | |_| |/ _` | '_ \ / _` | |/ _ \ '__/ __|
# |  _  | (_| | | | | (_| | |  __/ |  \__ \
# |_| |_|\__,_|_| |_|\__,_|_|\___|_|  |___/
                                         



class Handler(object):
  '''
  Base class for handlers. New handlers should subclass this class and provide the following methods:

  REQUIRED:
    test() - return true if the handle can handle.
    template() - return a template string for generating submit scripts.
    run() - a method that can run all of the scripts in stored in self.submit_scripts member.
  OPTIONAL:
    default_context() - return a dict containing context entries for template file rendering.
  '''
  def __init__(self,opts):
    self.opts = opts
    self.submit_scripts = list()
    self.tmpdir = None


  @staticmethod
  def test():
    return False

  def default_context(self):
    return dict()

  def generate_scripts(self,commands):

    # get user-supplied context
    user_context = dict()
    if self.opts.context_file:
      with open(self.opts.context_file,'r') as f:
        user_context.update(json.load(f))
    user_context.update(json.loads(self.opts.context))


    currdir = os.getcwd()
    self.tmpdir = tempfile.mkdtemp(prefix='run-')
    logging.info("using %s for temporary storage"%self.tmpdir)
    # create submission scripts. one for each command.
    for command in commands:
      context = self.default_context()
      try:
        context['CMD'],context['ARGS'] = command.strip().split(maxsplit=1)
      except:
        context['CMD'] = command
        context['ARGS'] = ""
      context['WORKDIR'] = currdir
      context['NAME'] = generate_name(command)

      context.update(user_context)

      # use template file if provided by user, otherwise use template provided by the handler.
      if self.opts.template:
        with open(self.opts.template,'r') as f:
          template = f.read()
      else:
        template = handler.template()

      if self.opts.print_template:
        print(template)
        sys.exit(0)

      submit_script_text = render(template,context)

      submit_script = "run-submit_script.%d"%len(self.submit_scripts)
      with workdir(self.tmpdir):
        with open(submit_script,'w') as f:
          f.write(submit_script_text)
        st = os.stat(submit_script)
        os.chmod(submit_script, st.st_mode | stat.S_IEXEC)
        self.submit_scripts.append( os.path.abspath( submit_script ) )
      
  def cleanup(self):
    if self.opts.leave_tempdir:
      print("Temporary directory '%s' left behind."%self.tmpdir)
    else:
      shutil.rmtree(self.tmpdir)
  



class SerialHandler(Handler):
  @staticmethod
  def test():
    # we can always run jobs in serial
    return True

  def template(self):
    return '''#! <%INTERPRETER%>

cd <%WORKDIR%>
echo "CMD: <%CMD%>"
echo "ARGS: <%ARGS%>"
echo -n "BEGIN: "
date +"%Y%m%d %H:%M:%S"
<%CMD%> <%ARGS%>
echo -n "END:   "
date +%"Y%m%d %H:%M:%S"
'''

  def default_context(self):
    context = dict()
    context['INTERPRETER'] = shutil.which("bash")

    return context


  def run(self):
    for file in self.submit_scripts:
      print("Running %s"%(file))
      run(file)



class xJobsHandler(SerialHandler):
  @staticmethod
  def test():
    return shutil.which("xjobs") is not None

  def run(self):
    run("xjobs", input=" ".join(self.submit_scripts))


class GnuParallelHandler(SerialHandler):
  @staticmethod
  def test():
    return shutil.which("parallel") is not None

  def run(self):
    run("parallel ::: "+" ".join(self.submit_scripts))

class SlurmHandler(SerialHandler):
  @staticmethod
  def test():
    return shutil.which("sbatch") is not None

  def run(self):
    for file in self.submit_scripts:
      run("sbatch %s"%file)

  def default_context(self):
    context = dict()
    context['INTERPRETER'] = shutil.which("bash")

    return context


  def template(self):
    serial_script = re.sub("#!.*","",super().template())

    return '''#! <%INTERPRETER%>

#SBATCH --job-name=<%NAME%>
#SBATCH --output=<%NAME%>.out
#SBATCH --time=0-01:00:00
#SBATCH --cpus-per-task=1
#SBATCH --nodes=1
##SBATCH --mem-per-cpu=1G

{SERIAL}

'''.format(SERIAL=serial_script)



#  __  __       _       
# |  \/  | __ _(_)_ __  
# | |\/| |/ _` | | '_ \ 
# | |  | | (_| | | | | |
# |_|  |_|\__,_|_|_| |_|
                      


clsmembers = [ cls for cls in inspect.getmembers(sys.modules[__name__], inspect.isclass) if cls[0].lower() != "handler" and cls[0].lower().endswith("handler") ]
handlers = { k.lower().replace("handler",""):v for (k,v) in clsmembers}
if __name__ == "__main__":
  parser = ArgumentParser(description="Quickly queue and run jobs from the command-line.")


  # old options
  # "block|B" => \$opt_block,
  # "args-are-run-scripts|F" => \$opt_args_are_run_scripts,
  # "leave-run-scripts|f" => \$opt_leave_run_scripts,
  # "handler_options|O=s" => \$opt_handler_options,
  # "list-handlers|l" => \$opt_list_handlers,
  # "output|o" => \$opt_output,
  # "readme|R" => \$opt_readme,
  # "verbose|v+" => \$opt_verbose,

  parser.add_argument("arguments",
                      action="store",
                      nargs='*',
                      default=list(),
                      help="A colon-delimited list of commands to run. Note that the delimiter character can be specified with the --delimiter option." )

  parser.add_argument("-m", "--manual",
                      action="store_true",
                      help="Print manual and exit." )

  parser.add_argument("-d", "--delimiter",
                      action="store",
                      default=":",
                      help="Use DELIMITER to delimiter commands." )

  parser.add_argument("-H", "--handler",
                      action="store",
                      help="Use HANDLER to submit jobs." )

  parser.add_argument("-t", "--template",
                      action="store",
                      help="Use TEMPLATE for submission script template." )

  parser.add_argument("-l","--list-handlers",
                      action="store_true",
                      default=False,
                      help="List supported handlers and exit." )

  parser.add_argument("--debug",
                      action="store_true",
                      default=False,
                      help="Turn on debugging output." )

  parser.add_argument("--print-template",
                      action="store_true",
                      default=False,
                      help="Print template submit script that will be used and exit." )

  parser.add_argument("--leave-tempdir",
                      action="store_true",
                      default=False,
                      help="Leave the temperary directory used to write submit scripts." )

  parser.add_argument("-n", "--dry-run",
                      action="store_true",
                      default=False,
                      help="Dry run. Don't actuall run submit scripts." )

  parser.add_argument("-C", "--command",
                      action="store",
                      default="",
                      help="Prepend COMMAND to all commands before running." )

  parser.add_argument("--context",
                      action="store",
                      default="{}",
                      help="A JSON formatted string containing key=value pairs that will be added to the context when rendering the submit script." )

  parser.add_argument("--context-file",
                      action="store",
                      help="A JSON file containing key=value pairs that will be added to the context when rendering the submit script." )


  args = parser.parse_args()

  if args.manual:
    print(__doc__)
    sys.exit()

  if args.list_handlers:
    print("{:15}{:15}".format("Handler","Available"))
    print("{:=<30}".format(""))
    for h in handlers:
      print("{:15}{:15}".format(h,"yes" if handlers[h].test() else "no" ))
    sys.exit()


  if args.debug:
    logging.basicConfig(level=logging.DEBUG)

  commands = [ (args.command+" "+cmd.strip()).strip() for cmd in " ".join(args.arguments).split(args.delimiter) ]


  if args.handler:
    handler = args.handler
  else:
    # detect handlers
    candidates = dict()
    for h in handlers:
      if handlers[h].test():
        logging.info("detected %s handler"%h)
        p = 1000
        if h in handler_priority:
          p = handler_priority.index(h)
        candidates[p] = h

    if len(candidates) < 1:
      raise RuntimeError("No candidates found to handle jub submission")
    
    # take handler with the highest priotity
    handler = [ candidates[h] for h in sorted(candidates) ][0]

  if handler not in handlers:
    raise RuntimeError("Handler '%s' is not supported. Did you spell the name correctly?")

  logging.info("using %s handler"%handler)

  handler = handlers[handler](args)
  handler.generate_scripts(commands)
  if not args.dry_run:
    handler.run()
  handler.cleanup()





